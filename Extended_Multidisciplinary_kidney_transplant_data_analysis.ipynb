{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## setup and basic analysis"
      ],
      "metadata": {
        "id": "e4gdl30peUz0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYTq_k5pdpem"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "class TransplantStudyAnalyzer:\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.raw_df = df\n",
        "        # Define visit identifiers based on completion flags\n",
        "        self.visit_identifiers = {\n",
        "            1: 'ast_transition_readiness_assessment_tool_late_tran_complete',\n",
        "            2: 'brief_2_behavior_rating_inventory_of_executive_fun_complete',\n",
        "            3: ['gad7_anxiety_complete', 'phq9_modified_for_teens_complete'],\n",
        "            4: ['social_needs_patient_questionnaire_complete', 'pittsburgh_sleep_quality_index_psqi_complete'],\n",
        "            5: 'pedsql_young_adult_quality_of_life_inventory_v40_y_complete',\n",
        "            6: 'brief_2_behavior_rating_inventory_of_executiv_4875_complete',\n",
        "            7: ['v2_gad_7_anxiety_complete', 'v2_phq9_modified_for_teens_complete'],\n",
        "            8: 'transition_readiness_checklist_late_transition_17_complete',\n",
        "            9: 'ast_transition_readiness_assessment_tool_late_tran_complete'\n",
        "        }\n",
        "\n",
        "        # Define domain columns\n",
        "        self.domain_columns = {\n",
        "            'Medical Knowledge': ['mt1_v2_v2', 'mt2_v2_v2', 'mt3_v2_v2', 'mt4_v2_v2', 'mt5_v2_v2'],\n",
        "            'Medication Management': ['mm6_v2_v2', 'mm7_v2_v2', 'mm8_v2_v2', 'mm9_v2_v2'],\n",
        "            'Healthcare Navigation': ['ad10_v2_v2', 'ad11_v2_v2', 'ad12_v2_v2', 'ad13_v2_v2'],\n",
        "            'Self-Advocacy': ['rb16_v2_v2', 'rb17_v2_v2']\n",
        "        }\n",
        "\n",
        "        # Clean and prepare data\n",
        "        self.clean_df = self._preprocess_data()\n",
        "\n",
        "    def _preprocess_data(self):\n",
        "        \"\"\"Clean and prepare data for analysis\"\"\"\n",
        "        df = self.raw_df.copy()\n",
        "\n",
        "        # Convert date columns\n",
        "        date_cols = [col for col in df.columns if 'date' in col.lower() or 'timestamp' in col.lower()]\n",
        "        for col in date_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "\n",
        "        # Convert numeric columns\n",
        "        score_cols = [\n",
        "            'ast_total_score',\n",
        "            'score_v2_85d59c',  # GAD-7\n",
        "            'phq_9_severity_score',  # PHQ-9\n",
        "            'global_psqi_score'  # Sleep quality\n",
        "        ]\n",
        "\n",
        "        for col in score_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "        # Convert domain columns\n",
        "        for domain_cols in self.domain_columns.values():\n",
        "            for prefix in domain_cols:\n",
        "                cols = [col for col in df.columns if col.startswith(prefix)]\n",
        "                for col in cols:\n",
        "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "        return df\n",
        "\n",
        "    def analyze_demographics(self):\n",
        "        \"\"\"Analyze demographic information\"\"\"\n",
        "        demographics = {\n",
        "            'total_patients': len(self.clean_df),\n",
        "            'age': {\n",
        "                'mean': self.clean_df['ba_age'].apply(pd.to_numeric, errors='coerce').mean(),\n",
        "                'std': self.clean_df['ba_age'].apply(pd.to_numeric, errors='coerce').std(),\n",
        "                'range': (\n",
        "                    self.clean_df['ba_age'].apply(pd.to_numeric, errors='coerce').min(),\n",
        "                    self.clean_df['ba_age'].apply(pd.to_numeric, errors='coerce').max()\n",
        "                )\n",
        "            },\n",
        "            'gender': self.clean_df['ba_gender'].value_counts().to_dict()\n",
        "        }\n",
        "        return demographics\n",
        "\n",
        "    def analyze_ast_scores(self):\n",
        "        \"\"\"Analyze AST scores\"\"\"\n",
        "        ast_data = self.clean_df['ast_total_score'].dropna()\n",
        "\n",
        "        results = {\n",
        "            'summary': {\n",
        "                'n': len(ast_data),\n",
        "                'mean': ast_data.mean(),\n",
        "                'std': ast_data.std(),\n",
        "                'median': ast_data.median(),\n",
        "                'range': (ast_data.min(), ast_data.max())\n",
        "            },\n",
        "            'completion_rate': (len(ast_data) / len(self.clean_df)) * 100,\n",
        "            'score_distribution': {\n",
        "                'below_mean': (ast_data < ast_data.mean()).sum(),\n",
        "                'above_mean': (ast_data >= ast_data.mean()).sum()\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Add quartile information\n",
        "        results['quartiles'] = {\n",
        "            '25th': ast_data.quantile(0.25),\n",
        "            'median': ast_data.quantile(0.50),\n",
        "            '75th': ast_data.quantile(0.75)\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def analyze_domain_scores(self):\n",
        "        \"\"\"Analyze scores across domains\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        for domain, col_prefixes in self.domain_columns.items():\n",
        "            domain_data = pd.DataFrame()\n",
        "\n",
        "            for prefix in col_prefixes:\n",
        "                cols = [col for col in self.clean_df.columns if col.startswith(prefix)]\n",
        "                if cols:\n",
        "                    data = self.clean_df[cols].apply(pd.to_numeric, errors='coerce')\n",
        "                    domain_data = pd.concat([domain_data, data], axis=1)\n",
        "\n",
        "            if not domain_data.empty:\n",
        "                results[domain] = {\n",
        "                    'mean': domain_data.mean().mean(),\n",
        "                    'std': domain_data.std().mean(),\n",
        "                    'completion_rate': (domain_data.notna().sum().sum() /\n",
        "                                      (domain_data.shape[0] * domain_data.shape[1]) * 100),\n",
        "                    'items_completed': domain_data.notna().sum().sum(),\n",
        "                    'total_items': domain_data.shape[0] * domain_data.shape[1]\n",
        "                }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def analyze_mental_health(self):\n",
        "        \"\"\"Analyze mental health measures (GAD-7 and PHQ-9)\"\"\"\n",
        "        mental_health = {\n",
        "            'GAD-7': self._analyze_mental_health_measure('score_v2_85d59c', 'GAD-7'),\n",
        "            'PHQ-9': self._analyze_mental_health_measure('phq_9_severity_score', 'PHQ-9')\n",
        "        }\n",
        "        return mental_health\n",
        "\n",
        "    def _analyze_mental_health_measure(self, column: str, measure_type: str):\n",
        "        \"\"\"Helper function to analyze mental health measures\"\"\"\n",
        "        data = self.clean_df[column].dropna()\n",
        "\n",
        "        if len(data) == 0:\n",
        "            return None\n",
        "\n",
        "        results = {\n",
        "            'mean': data.mean(),\n",
        "            'std': data.std(),\n",
        "            'median': data.median(),\n",
        "            'range': (data.min(), data.max()),\n",
        "            'completion_rate': (len(data) / len(self.clean_df)) * 100\n",
        "        }\n",
        "\n",
        "        # Add severity categories\n",
        "        if measure_type == 'GAD-7':\n",
        "            results['severity'] = {\n",
        "                'minimal': (data <= 4).sum(),\n",
        "                'mild': ((data > 4) & (data <= 9)).sum(),\n",
        "                'moderate': ((data > 9) & (data <= 14)).sum(),\n",
        "                'severe': (data > 14).sum()\n",
        "            }\n",
        "        elif measure_type == 'PHQ-9':\n",
        "            results['severity'] = {\n",
        "                'minimal': (data <= 4).sum(),\n",
        "                'mild': ((data > 4) & (data <= 9)).sum(),\n",
        "                'moderate': ((data > 9) & (data <= 14)).sum(),\n",
        "                'moderately_severe': ((data > 14) & (data <= 19)).sum(),\n",
        "                'severe': (data > 19).sum()\n",
        "            }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def create_visualizations(self):\n",
        "        \"\"\"Create comprehensive visualization suite\"\"\"\n",
        "        figs = {}\n",
        "\n",
        "        # 1. AST Score Distribution\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        ast_data = self.clean_df['ast_total_score'].dropna()\n",
        "        if len(ast_data) > 0:\n",
        "            sns.histplot(ast_data, ax=ax)\n",
        "            ax.axvline(ast_data.mean(), color='r', linestyle='--', label='Mean')\n",
        "            ax.axvline(ast_data.median(), color='g', linestyle='--', label='Median')\n",
        "            ax.set_title('Distribution of AST Scores')\n",
        "            ax.set_xlabel('Score')\n",
        "            ax.set_ylabel('Frequency')\n",
        "            ax.legend()\n",
        "        figs['ast_distribution'] = fig\n",
        "\n",
        "        # 2. Domain Scores\n",
        "        domain_scores = self.analyze_domain_scores()\n",
        "        if domain_scores:\n",
        "            fig, ax = plt.subplots(figsize=(12, 6))\n",
        "            domains = list(domain_scores.keys())\n",
        "            means = [scores['mean'] for scores in domain_scores.values()]\n",
        "\n",
        "            ax.bar(range(len(domains)), means)\n",
        "            ax.set_xticks(range(len(domains)))\n",
        "            ax.set_xticklabels(domains, rotation=45)\n",
        "            ax.set_title('Mean Domain Scores')\n",
        "            ax.set_ylabel('Score')\n",
        "            figs['domain_scores'] = fig\n",
        "\n",
        "        # 3. Mental Health Scores\n",
        "        mental_health = self.analyze_mental_health()\n",
        "        if mental_health['GAD-7'] and mental_health['PHQ-9']:\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "            # GAD-7 Severity Distribution\n",
        "            labels = list(mental_health['GAD-7']['severity'].keys())\n",
        "            sizes = list(mental_health['GAD-7']['severity'].values())\n",
        "            ax1.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
        "            ax1.set_title('GAD-7 Severity Distribution')\n",
        "\n",
        "            # PHQ-9 Severity Distribution\n",
        "            labels = list(mental_health['PHQ-9']['severity'].keys())\n",
        "            sizes = list(mental_health['PHQ-9']['severity'].values())\n",
        "            ax2.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
        "            ax2.set_title('PHQ-9 Severity Distribution')\n",
        "\n",
        "            figs['mental_health'] = fig\n",
        "\n",
        "        return figs\n",
        "\n",
        "    def generate_report(self):\n",
        "        \"\"\"Generate comprehensive analysis report\"\"\"\n",
        "        report = {\n",
        "            'demographics': self.analyze_demographics(),\n",
        "            'ast_analysis': self.analyze_ast_scores(),\n",
        "            'domain_analysis': self.analyze_domain_scores(),\n",
        "            'mental_health': self.analyze_mental_health()\n",
        "        }\n",
        "        return report\n",
        "\n",
        "    def print_summary(self):\n",
        "        \"\"\"Print analysis summary\"\"\"\n",
        "        report = self.generate_report()\n",
        "\n",
        "        print(\"\\n=== TRANSPLANT STUDY ANALYSIS SUMMARY ===\\n\")\n",
        "\n",
        "        # Demographics\n",
        "        demo = report['demographics']\n",
        "        print(\"Demographics:\")\n",
        "        print(f\"Total participants: {demo['total_patients']}\")\n",
        "        print(f\"Age range: {demo['age']['range'][0]:.1f} - {demo['age']['range'][1]:.1f} years\")\n",
        "        print(f\"Mean age: {demo['age']['mean']:.1f} years (SD: {demo['age']['std']:.1f})\")\n",
        "\n",
        "        # AST Scores\n",
        "        ast = report['ast_analysis']\n",
        "        print(\"\\nAST Scores Summary:\")\n",
        "        print(f\"Number of participants: {ast['summary']['n']}\")\n",
        "        print(f\"Mean score: {ast['summary']['mean']:.2f} (SD: {ast['summary']['std']:.2f})\")\n",
        "        print(f\"Score range: {ast['summary']['range'][0]:.1f} - {ast['summary']['range'][1]:.1f}\")\n",
        "        print(f\"Completion rate: {ast['completion_rate']:.1f}%\")\n",
        "\n",
        "        # Domain Scores\n",
        "        print(\"\\nDomain Scores:\")\n",
        "        for domain, scores in report['domain_analysis'].items():\n",
        "            print(f\"\\n{domain}:\")\n",
        "            print(f\"  Mean: {scores['mean']:.2f} (SD: {scores['std']:.2f})\")\n",
        "            print(f\"  Completion Rate: {scores['completion_rate']:.1f}%\")\n",
        "\n",
        "        # Mental Health\n",
        "        print(\"\\nMental Health Measures:\")\n",
        "        mh = report['mental_health']\n",
        "        for measure, data in mh.items():\n",
        "            if data:\n",
        "                print(f\"\\n{measure}:\")\n",
        "                print(f\"  Mean score: {data['mean']:.2f} (SD: {data['std']:.2f})\")\n",
        "                print(f\"  Completion rate: {data['completion_rate']:.1f}%\")\n",
        "                print(\"  Severity distribution:\")\n",
        "                for category, count in data['severity'].items():\n",
        "                    print(f\"    {category}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced analysis"
      ],
      "metadata": {
        "id": "amtuc5a0fmG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TransplantStudyAdvancedAnalysis:\n",
        "    def __init__(self, base_analyzer):\n",
        "        \"\"\"Initialize with base analyzer instance\"\"\"\n",
        "        self.base = base_analyzer\n",
        "        self.df = base_analyzer.clean_df\n",
        "\n",
        "    def analyze_longitudinal_changes(self):\n",
        "        \"\"\"Analyze changes between paired visits\"\"\"\n",
        "        visit_pairs = {\n",
        "            'AST_Readiness': (1, 9),\n",
        "            'BRIEF': (2, 6),\n",
        "            'Mental_Health': (3, 7)\n",
        "        }\n",
        "\n",
        "        changes = {}\n",
        "        for measure, (visit1, visit2) in visit_pairs.items():\n",
        "            changes[measure] = self._analyze_visit_pair(visit1, visit2)\n",
        "\n",
        "        return changes\n",
        "\n",
        "    def _analyze_visit_pair(self, visit1: int, visit2: int) -> Dict:\n",
        "        \"\"\"Analyze changes between two visits\"\"\"\n",
        "        visit1_mask = self.df[self.base.visit_identifiers[visit1]] == 2\n",
        "        visit2_mask = self.df[self.base.visit_identifiers[visit2]] == 2\n",
        "\n",
        "        visit1_data = self.df[visit1_mask]\n",
        "        visit2_data = self.df[visit2_mask]\n",
        "\n",
        "        # Find common participants\n",
        "        common_participants = set(visit1_data.index) & set(visit2_data.index)\n",
        "\n",
        "        if not common_participants:\n",
        "            return {\n",
        "                'n_pairs': 0,\n",
        "                'error': 'No matching pairs found'\n",
        "            }\n",
        "\n",
        "        paired_data = {\n",
        "            'n_pairs': len(common_participants),\n",
        "            'completion_rate': (len(common_participants) / len(self.df)) * 100,\n",
        "            'changes': self._calculate_changes(\n",
        "                visit1_data.loc[common_participants],\n",
        "                visit2_data.loc[common_participants]\n",
        "            )\n",
        "        }\n",
        "\n",
        "        return paired_data\n",
        "\n",
        "    def analyze_patient_caregiver_agreement(self):\n",
        "        \"\"\"Analyze agreement between patient and caregiver responses\"\"\"\n",
        "        measures = {\n",
        "            'BRIEF': {\n",
        "                'patient_cols': [col for col in self.df.columns if col.startswith('brief2_')],\n",
        "                'caregiver_cols': [col for col in self.df.columns if col.startswith('brief2_parent_')]\n",
        "            },\n",
        "            'PedsQL': {\n",
        "                'patient_cols': [col for col in self.df.columns if col.startswith('pedsql_adult_')],\n",
        "                'caregiver_cols': [col for col in self.df.columns if col.startswith('pedsql_you_par')]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        agreement = {}\n",
        "        for measure, cols in measures.items():\n",
        "            agreement[measure] = self._calculate_agreement(\n",
        "                cols['patient_cols'],\n",
        "                cols['caregiver_cols']\n",
        "            )\n",
        "\n",
        "        return agreement\n",
        "\n",
        "    def analyze_risk_factors(self):\n",
        "        \"\"\"Analyze potential risk factors for poor outcomes\"\"\"\n",
        "        ast_scores = self.df['ast_total_score']\n",
        "        risk_analysis = {\n",
        "            'age_correlation': self._correlate_with_outcome('ba_age', ast_scores),\n",
        "            'mental_health_correlation': {\n",
        "                'anxiety': self._correlate_with_outcome('score_v2_85d59c', ast_scores),\n",
        "                'depression': self._correlate_with_outcome('phq_9_severity_score', ast_scores)\n",
        "            },\n",
        "            'sleep_correlation': self._correlate_with_outcome('global_psqi_score', ast_scores)\n",
        "        }\n",
        "\n",
        "        return risk_analysis\n",
        "\n",
        "    def create_advanced_visualizations(self):\n",
        "        \"\"\"Create advanced visualization suite\"\"\"\n",
        "        figs = {}\n",
        "\n",
        "        # 1. Longitudinal Changes\n",
        "        longitudinal = self.analyze_longitudinal_changes()\n",
        "        fig, axes = plt.subplots(1, len(longitudinal), figsize=(15, 5))\n",
        "        for i, (measure, data) in enumerate(longitudinal.items()):\n",
        "            if 'changes' in data:\n",
        "                axes[i].boxplot(data['changes'])\n",
        "                axes[i].set_title(f'{measure} Changes')\n",
        "        figs['longitudinal'] = fig\n",
        "\n",
        "        # 2. Patient-Caregiver Agreement\n",
        "        agreement = self.analyze_patient_caregiver_agreement()\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        measures = list(agreement.keys())\n",
        "        agreement_scores = [data['icc'] for data in agreement.values()]\n",
        "        ax.bar(measures, agreement_scores)\n",
        "        ax.set_title('Patient-Caregiver Agreement (ICC)')\n",
        "        figs['agreement'] = fig\n",
        "\n",
        "        # 3. Risk Factor Analysis\n",
        "        risk_factors = self.analyze_risk_factors()\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "\n",
        "        # Age correlation\n",
        "        self._plot_correlation(axes[0,0], 'ba_age', 'ast_total_score', 'Age vs AST Score')\n",
        "\n",
        "        # Mental health correlations\n",
        "        self._plot_correlation(axes[0,1], 'score_v2_85d59c', 'ast_total_score', 'Anxiety vs AST Score')\n",
        "        self._plot_correlation(axes[1,0], 'phq_9_severity_score', 'ast_total_score', 'Depression vs AST Score')\n",
        "\n",
        "        # Sleep correlation\n",
        "        self._plot_correlation(axes[1,1], 'global_psqi_score', 'ast_total_score', 'Sleep Quality vs AST Score')\n",
        "\n",
        "        figs['risk_factors'] = fig\n",
        "\n",
        "        return figs\n",
        "\n",
        "    def generate_clinical_recommendations(self):\n",
        "        \"\"\"Generate clinical recommendations based on analysis\"\"\"\n",
        "        ast_analysis = self.base.analyze_ast_scores()\n",
        "        domain_analysis = self.base.analyze_domain_scores()\n",
        "        mental_health = self.base.analyze_mental_health()\n",
        "\n",
        "        recommendations = {\n",
        "            'high_risk_patients': self._identify_high_risk_patients(),\n",
        "            'domain_specific': self._generate_domain_recommendations(domain_analysis),\n",
        "            'mental_health': self._generate_mental_health_recommendations(mental_health),\n",
        "            'general': self._generate_general_recommendations(ast_analysis)\n",
        "        }\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def export_results(self, filename: str):\n",
        "        \"\"\"Export analysis results to Excel\"\"\"\n",
        "        with pd.ExcelWriter(filename) as writer:\n",
        "            # Basic analysis\n",
        "            pd.DataFrame(self.base.analyze_demographics()).to_excel(\n",
        "                writer, sheet_name='Demographics'\n",
        "            )\n",
        "            pd.DataFrame(self.base.analyze_ast_scores()).to_excel(\n",
        "                writer, sheet_name='AST_Scores'\n",
        "            )\n",
        "\n",
        "            # Domain analysis\n",
        "            pd.DataFrame(self.base.analyze_domain_scores()).to_excel(\n",
        "                writer, sheet_name='Domain_Scores'\n",
        "            )\n",
        "\n",
        "            # Mental health\n",
        "            pd.DataFrame(self.base.analyze_mental_health()).to_excel(\n",
        "                writer, sheet_name='Mental_Health'\n",
        "            )\n",
        "\n",
        "            # Advanced analysis\n",
        "            pd.DataFrame(self.analyze_longitudinal_changes()).to_excel(\n",
        "                writer, sheet_name='Longitudinal'\n",
        "            )\n",
        "            pd.DataFrame(self.analyze_patient_caregiver_agreement()).to_excel(\n",
        "                writer, sheet_name='Agreement'\n",
        "            )\n",
        "            pd.DataFrame(self.analyze_risk_factors()).to_excel(\n",
        "                writer, sheet_name='Risk_Factors'\n",
        "            )\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run complete analysis\"\"\"\n",
        "    try:\n",
        "        # Load data\n",
        "        df = pd.read_csv('/content/ExtendedMultidiscipl_DATA_2024-10-22_1316.csv')\n",
        "\n",
        "        # Create base analyzer\n",
        "        base_analyzer = TransplantStudyAnalyzer(df)\n",
        "\n",
        "        # Create advanced analyzer\n",
        "        advanced_analyzer = TransplantStudyAdvancedAnalysis(base_analyzer)\n",
        "\n",
        "        # Generate reports\n",
        "        basic_report = base_analyzer.generate_report()\n",
        "        advanced_report = {\n",
        "            'longitudinal': advanced_analyzer.analyze_longitudinal_changes(),\n",
        "            'agreement': advanced_analyzer.analyze_patient_caregiver_agreement(),\n",
        "            'risk_factors': advanced_analyzer.analyze_risk_factors()\n",
        "        }\n",
        "\n",
        "        # Create visualizations\n",
        "        basic_viz = base_analyzer.create_visualizations()\n",
        "        advanced_viz = advanced_analyzer.create_advanced_visualizations()\n",
        "\n",
        "        # Generate recommendations\n",
        "        recommendations = advanced_analyzer.generate_clinical_recommendations()\n",
        "\n",
        "        # Export results\n",
        "        advanced_analyzer.export_results('transplant_analysis_results.xlsx')\n",
        "\n",
        "        # Print summaries\n",
        "        base_analyzer.print_summary()\n",
        "        print(\"\\nAnalysis complete. Results exported to 'transplant_analysis_results.xlsx'\")\n",
        "\n",
        "        # Show visualizations\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in analysis: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv('/content/ExtendedMultidiscipl_DATA_2024-10-22_1316.csv')\n",
        "\n",
        "# Create analyzers\n",
        "base_analyzer = TransplantStudyAnalyzer(df)\n",
        "advanced_analyzer = TransplantStudyAdvancedAnalysis(base_analyzer)\n",
        "\n",
        "# Generate reports\n",
        "basic_report = base_analyzer.generate_report()\n",
        "advanced_report = {\n",
        "    'longitudinal': advanced_analyzer.analyze_longitudinal_changes(),\n",
        "    'agreement': advanced_analyzer.analyze_patient_caregiver_agreement(),\n",
        "    'risk_factors': advanced_analyzer.analyze_risk_factors()\n",
        "}\n",
        "\n",
        "# Create visualizations\n",
        "basic_viz = base_analyzer.create_visualizations()\n",
        "advanced_viz = advanced_analyzer.create_advanced_visualizations()\n",
        "\n",
        "# Generate recommendations\n",
        "recommendations = advanced_analyzer.generate_clinical_recommendations()\n",
        "\n",
        "# Export results\n",
        "advanced_analyzer.export_results('transplant_analysis_results.xlsx')\n",
        "\n",
        "# Print summary and show visualizations\n",
        "base_analyzer.print_summary()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "mwotDjSPfoT1",
        "outputId": "f428a610-15d9-4b9a-a92a-f29975c33d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in analysis: 'TransplantStudyAdvancedAnalysis' object has no attribute '_calculate_changes'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TransplantStudyAdvancedAnalysis' object has no attribute '_calculate_changes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a0b5de4aa41e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0mbasic_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m advanced_report = {\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;34m'longitudinal'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madvanced_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_longitudinal_changes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;34m'agreement'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madvanced_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_patient_caregiver_agreement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;34m'risk_factors'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madvanced_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_risk_factors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-a0b5de4aa41e>\u001b[0m in \u001b[0;36manalyze_longitudinal_changes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mchanges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvisit1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisit2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvisit_pairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mchanges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_analyze_visit_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisit1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisit2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchanges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-a0b5de4aa41e>\u001b[0m in \u001b[0;36m_analyze_visit_pair\u001b[0;34m(self, visit1, visit2)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;34m'n_pairs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_participants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;34m'completion_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_participants\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             'changes': self._calculate_changes(\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mvisit1_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcommon_participants\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mvisit2_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcommon_participants\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TransplantStudyAdvancedAnalysis' object has no attribute '_calculate_changes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "class TransplantStudyAdvancedAnalysis:\n",
        "    def __init__(self, base_analyzer):\n",
        "        self.base = base_analyzer\n",
        "        self.df = base_analyzer.clean_df\n",
        "\n",
        "    def _clean_numeric_data(self, series: pd.Series) -> pd.Series:\n",
        "        \"\"\"Convert series to numeric, handling errors\"\"\"\n",
        "        return pd.to_numeric(series, errors='coerce')\n",
        "\n",
        "    def _calculate_changes(self, data1: pd.DataFrame, data2: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate changes between two timepoints\"\"\"\n",
        "        try:\n",
        "            changes = {}\n",
        "\n",
        "            # Calculate AST score changes\n",
        "            if 'ast_total_score' in data1.columns and 'ast_total_score' in data2.columns:\n",
        "                ast1 = self._clean_numeric_data(data1['ast_total_score'])\n",
        "                ast2 = self._clean_numeric_data(data2['ast_total_score'])\n",
        "\n",
        "                # Calculate differences\n",
        "                valid_mask = ~(ast1.isna() | ast2.isna())\n",
        "                if valid_mask.any():\n",
        "                    diff = ast2[valid_mask] - ast1[valid_mask]\n",
        "                    changes['ast_total_score'] = {\n",
        "                        'mean_change': diff.mean(),\n",
        "                        'std_change': diff.std(),\n",
        "                        'n_improved': (diff > 0).sum(),\n",
        "                        'n_declined': (diff < 0).sum(),\n",
        "                        'n_unchanged': (diff == 0).sum()\n",
        "                    }\n",
        "\n",
        "            # Calculate domain changes\n",
        "            if hasattr(self.base, 'domain_columns'):\n",
        "                for domain, columns in self.base.domain_columns.items():\n",
        "                    domain_cols = [col for col in data1.columns if any(c in col for c in columns)]\n",
        "                    if domain_cols:\n",
        "                        score1 = data1[domain_cols].apply(pd.to_numeric, errors='coerce').mean(axis=1)\n",
        "                        score2 = data2[domain_cols].apply(pd.to_numeric, errors='coerce').mean(axis=1)\n",
        "\n",
        "                        valid_mask = ~(score1.isna() | score2.isna())\n",
        "                        if valid_mask.any():\n",
        "                            diff = score2[valid_mask] - score1[valid_mask]\n",
        "                            changes[domain] = {\n",
        "                                'mean_change': diff.mean(),\n",
        "                                'std_change': diff.std(),\n",
        "                                'n_improved': (diff > 0).sum(),\n",
        "                                'n_declined': (diff < 0).sum()\n",
        "                            }\n",
        "\n",
        "            return changes\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating changes: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def analyze_longitudinal_changes(self) -> Dict:\n",
        "        \"\"\"Analyze changes between paired visits\"\"\"\n",
        "        try:\n",
        "            changes = {}\n",
        "\n",
        "            # Define visit pairs to analyze\n",
        "            visit_pairs = [\n",
        "                (1, 9),  # AST Assessment\n",
        "                (2, 6),  # BRIEF\n",
        "                (3, 7)   # Mental Health\n",
        "            ]\n",
        "\n",
        "            for visit1, visit2 in visit_pairs:\n",
        "                # Get data for each visit\n",
        "                data1 = self.df[self.df[f'visit_{visit1}_complete'] == 2].copy()\n",
        "                data2 = self.df[self.df[f'visit_{visit2}_complete'] == 2].copy()\n",
        "\n",
        "                if not data1.empty and not data2.empty:\n",
        "                    changes[f'Visit_{visit1}_to_{visit2}'] = self._calculate_changes(data1, data2)\n",
        "\n",
        "            return changes\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in longitudinal analysis: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def analyze_patient_caregiver_agreement(self) -> Dict:\n",
        "        \"\"\"Analyze agreement between patient and caregiver responses\"\"\"\n",
        "        try:\n",
        "            agreement = {}\n",
        "\n",
        "            # BRIEF agreement\n",
        "            brief_patient = [col for col in self.df.columns if col.startswith('brief2_') and 'parent' not in col]\n",
        "            brief_caregiver = [col for col in self.df.columns if 'brief2_parent_' in col]\n",
        "\n",
        "            if brief_patient and brief_caregiver:\n",
        "                patient_scores = self.df[brief_patient].apply(pd.to_numeric, errors='coerce').mean(axis=1)\n",
        "                caregiver_scores = self.df[brief_caregiver].apply(pd.to_numeric, errors='coerce').mean(axis=1)\n",
        "\n",
        "                agreement['BRIEF'] = self._calculate_agreement(patient_scores, caregiver_scores)\n",
        "\n",
        "            # QoL agreement\n",
        "            qol_patient = [col for col in self.df.columns if col.startswith('pedsql_adult_')]\n",
        "            qol_caregiver = [col for col in self.df.columns if col.startswith('pedsql_you_par')]\n",
        "\n",
        "            if qol_patient and qol_caregiver:\n",
        "                patient_scores = self.df[qol_patient].apply(pd.to_numeric, errors='coerce').mean(axis=1)\n",
        "                caregiver_scores = self.df[qol_caregiver].apply(pd.to_numeric, errors='coerce').mean(axis=1)\n",
        "\n",
        "                agreement['QoL'] = self._calculate_agreement(patient_scores, caregiver_scores)\n",
        "\n",
        "            return agreement\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in agreement analysis: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def _calculate_agreement(self, series1: pd.Series, series2: pd.Series) -> Dict:\n",
        "        \"\"\"Calculate agreement statistics between two series\"\"\"\n",
        "        try:\n",
        "            # Remove missing values\n",
        "            valid_mask = ~(series1.isna() | series2.isna())\n",
        "            s1 = series1[valid_mask]\n",
        "            s2 = series2[valid_mask]\n",
        "\n",
        "            if len(s1) < 2:\n",
        "                return {\n",
        "                    'n_pairs': 0,\n",
        "                    'correlation': np.nan,\n",
        "                    'mean_difference': np.nan,\n",
        "                    'agreement_rate': np.nan\n",
        "                }\n",
        "\n",
        "            return {\n",
        "                'n_pairs': len(s1),\n",
        "                'correlation': stats.pearsonr(s1, s2)[0],\n",
        "                'mean_difference': (s1 - s2).mean(),\n",
        "                'agreement_rate': (abs(s1 - s2) < 10).mean() * 100  # Within 10 points\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating agreement: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def generate_report(self) -> Dict:\n",
        "        \"\"\"Generate comprehensive analysis report\"\"\"\n",
        "        try:\n",
        "            report = {\n",
        "                'longitudinal_analysis': self.analyze_longitudinal_changes(),\n",
        "                'agreement_analysis': self.analyze_patient_caregiver_agreement()\n",
        "            }\n",
        "\n",
        "            return report\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating report: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def create_visualizations(self) -> Dict:\n",
        "        \"\"\"Create visualization suite\"\"\"\n",
        "        try:\n",
        "            figs = {}\n",
        "\n",
        "            # Longitudinal changes visualization\n",
        "            changes = self.analyze_longitudinal_changes()\n",
        "            if changes:\n",
        "                fig, ax = plt.subplots(figsize=(10, 6))\n",
        "                visits = list(changes.keys())\n",
        "                improvements = [data['ast_total_score']['n_improved']\n",
        "                              for data in changes.values()\n",
        "                              if 'ast_total_score' in data]\n",
        "\n",
        "                ax.bar(visits, improvements)\n",
        "                ax.set_title('Number of Improved Patients Across Visits')\n",
        "                ax.set_xlabel('Visit Comparison')\n",
        "                ax.set_ylabel('Number of Improved Patients')\n",
        "                plt.xticks(rotation=45)\n",
        "                figs['longitudinal'] = fig\n",
        "\n",
        "            # Agreement visualization\n",
        "            agreement = self.analyze_patient_caregiver_agreement()\n",
        "            if agreement:\n",
        "                fig, ax = plt.subplots(figsize=(8, 6))\n",
        "                measures = list(agreement.keys())\n",
        "                correlations = [data['correlation'] for data in agreement.values()]\n",
        "\n",
        "                ax.bar(measures, correlations)\n",
        "                ax.set_title('Patient-Caregiver Agreement')\n",
        "                ax.set_ylabel('Correlation')\n",
        "                figs['agreement'] = fig\n",
        "\n",
        "            return figs\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating visualizations: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "\n",
        "\n",
        "#To use this class:\n",
        "\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/ExtendedMultidiscipl_DATA_2024-10-22_1316.csv')\n",
        "\n",
        "# Create analyzers\n",
        "base_analyzer = TransplantStudyAnalyzer(df)\n",
        "advanced_analyzer = TransplantStudyAdvancedAnalysis(base_analyzer)\n",
        "\n",
        "try:\n",
        "    # Generate report\n",
        "    report = advanced_analyzer.generate_report()\n",
        "\n",
        "    # Create visualizations\n",
        "    vizs = advanced_analyzer.create_visualizations()\n",
        "\n",
        "    # Show visualizations\n",
        "    plt.show()\n",
        "\n",
        "    # Print report summary\n",
        "    print(\"\\nLongitudinal Analysis Results:\")\n",
        "    for visit, changes in report['longitudinal_analysis'].items():\n",
        "        if 'ast_total_score' in changes:\n",
        "            print(f\"\\n{visit}:\")\n",
        "            print(f\"Improved: {changes['ast_total_score']['n_improved']}\")\n",
        "            print(f\"Declined: {changes['ast_total_score']['n_declined']}\")\n",
        "\n",
        "    print(\"\\nAgreement Analysis Results:\")\n",
        "    for measure, stats in report['agreement_analysis'].items():\n",
        "        print(f\"\\n{measure}:\")\n",
        "        print(f\"Correlation: {stats['correlation']:.2f}\")\n",
        "        print(f\"Agreement Rate: {stats['agreement_rate']:.1f}%\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error in analysis: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "0xFJ_l4i7hMj",
        "outputId": "b8d9122c-9449-4369-9b7a-2b694e26e8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in longitudinal analysis: 'visit_1_complete'\n",
            "Error in longitudinal analysis: 'visit_1_complete'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Longitudinal Analysis Results:\n",
            "\n",
            "Agreement Analysis Results:\n",
            "\n",
            "BRIEF:\n",
            "Correlation: 0.51\n",
            "Agreement Rate: 100.0%\n",
            "\n",
            "QoL:\n",
            "Correlation: nan\n",
            "Agreement Rate: nan%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statistical Analysis"
      ],
      "metadata": {
        "id": "quuxCh0x8B_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import scipy.stats as stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Optional, Union\n",
        "\n",
        "class TransplantStudyStatistics:\n",
        "    \"\"\"\n",
        "    Enhanced statistical analysis for transplant study data\n",
        "\n",
        "    This class provides comprehensive statistical testing and analysis methods\n",
        "    for the transplant study data, including:\n",
        "    - Longitudinal change analysis\n",
        "    - Inter-rater reliability\n",
        "    - Effect size calculations\n",
        "    - Multiple comparison corrections\n",
        "    - Power analysis\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_analyzer):\n",
        "        \"\"\"\n",
        "        Initialize with base analyzer instance\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        base_analyzer : TransplantStudyAnalyzer\n",
        "            Instance of the base analyzer containing cleaned data\n",
        "        \"\"\"\n",
        "        self.base = base_analyzer\n",
        "        self.df = base_analyzer.clean_df\n",
        "        self.alpha = 0.05  # Significance level\n",
        "\n",
        "    def analyze_longitudinal_effects(self,\n",
        "                                   measure: str,\n",
        "                                   visits: List[int]) -> Dict[str, Union[float, Dict]]:\n",
        "        \"\"\"\n",
        "        Analyze longitudinal effects for specified measure across visits\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        measure : str\n",
        "            Name of the measure to analyze (e.g., 'ast_total_score')\n",
        "        visits : List[int]\n",
        "            List of visit numbers to include\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        Dict containing:\n",
        "            - Repeated measures ANOVA results\n",
        "            - Effect sizes\n",
        "            - Post-hoc comparisons\n",
        "            - Power analysis\n",
        "        \"\"\"\n",
        "        # Collect data across visits\n",
        "        visit_data = []\n",
        "        for visit in visits:\n",
        "            mask = self.df[self.base.visit_identifiers[visit]] == 2\n",
        "            visit_data.append(self.df[mask][measure].dropna())\n",
        "\n",
        "        # Perform repeated measures ANOVA\n",
        "        f_stat, p_value = stats.f_oneway(*visit_data)\n",
        "\n",
        "        # Calculate effect size (partial eta-squared)\n",
        "        df_between = len(visits) - 1\n",
        "        df_within = sum(len(x) for x in visit_data) - len(visits)\n",
        "        eta_squared = (f_stat * df_between) / (f_stat * df_between + df_within)\n",
        "\n",
        "        # Perform post-hoc tests\n",
        "        if len(visits) > 2:\n",
        "            data = np.concatenate(visit_data)\n",
        "            groups = np.repeat(visits, [len(x) for x in visit_data])\n",
        "            posthoc = pairwise_tukeyhsd(data, groups)\n",
        "            posthoc_results = {\n",
        "                f\"Visit {i} vs Visit {j}\": {\n",
        "                    'diff': diff,\n",
        "                    'p-value': p,\n",
        "                    'significant': p < self.alpha\n",
        "                }\n",
        "                for (i, j), diff, p in zip(\n",
        "                    [(visits[i], visits[j])\n",
        "                     for i in range(len(visits))\n",
        "                     for j in range(i+1, len(visits))],\n",
        "                    posthoc.meandiffs,\n",
        "                    posthoc.pvalues\n",
        "                )\n",
        "            }\n",
        "        else:\n",
        "            posthoc_results = None\n",
        "\n",
        "        return {\n",
        "            'anova': {\n",
        "                'f_statistic': f_stat,\n",
        "                'p_value': p_value,\n",
        "                'significant': p_value < self.alpha\n",
        "            },\n",
        "            'effect_size': {\n",
        "                'partial_eta_squared': eta_squared,\n",
        "                'interpretation': self._interpret_effect_size(eta_squared)\n",
        "            },\n",
        "            'post_hoc': posthoc_results,\n",
        "            'power_analysis': self._compute_power_analysis(f_stat,\n",
        "                                                         df_between,\n",
        "                                                         df_within)\n",
        "        }\n",
        "\n",
        "    def analyze_patient_caregiver_agreement(self,\n",
        "                                          measure: str,\n",
        "                                          patient_cols: List[str],\n",
        "                                          caregiver_cols: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze agreement between patient and caregiver responses\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        measure : str\n",
        "            Name of the measure being analyzed\n",
        "        patient_cols : List[str]\n",
        "            List of columns containing patient responses\n",
        "        caregiver_cols : List[str]\n",
        "            List of columns containing caregiver responses\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        Dict containing:\n",
        "            - ICC\n",
        "            - Kappa statistics\n",
        "            - Bland-Altman analysis\n",
        "            - Agreement categories\n",
        "        \"\"\"\n",
        "        # Calculate means for patient and caregiver responses\n",
        "        patient_means = self.df[patient_cols].mean(axis=1)\n",
        "        caregiver_means = self.df[caregiver_cols].mean(axis=1)\n",
        "\n",
        "        # Drop missing pairs\n",
        "        valid_mask = ~(patient_means.isna() | caregiver_means.isna())\n",
        "        patient_means = patient_means[valid_mask]\n",
        "        caregiver_means = caregiver_means[valid_mask]\n",
        "\n",
        "        if len(patient_means) < 2:\n",
        "            return {'error': 'Insufficient paired data'}\n",
        "\n",
        "        # Calculate ICC\n",
        "        icc = self._calculate_icc(patient_means, caregiver_means)\n",
        "\n",
        "        # Calculate Kappa for categorized responses\n",
        "        kappa = self._calculate_kappa(patient_means, caregiver_means)\n",
        "\n",
        "        # Perform Bland-Altman analysis\n",
        "        bland_altman = self._bland_altman_analysis(patient_means, caregiver_means)\n",
        "\n",
        "        return {\n",
        "            'measure': measure,\n",
        "            'n_pairs': len(patient_means),\n",
        "            'icc': {\n",
        "                'value': icc,\n",
        "                'interpretation': self._interpret_icc(icc)\n",
        "            },\n",
        "            'kappa': {\n",
        "                'value': kappa,\n",
        "                'interpretation': self._interpret_kappa(kappa)\n",
        "            },\n",
        "            'bland_altman': bland_altman,\n",
        "            'agreement_categories': self._categorize_agreement(\n",
        "                patient_means, caregiver_means)\n",
        "        }\n",
        "\n",
        "    def analyze_predictors(self,\n",
        "                         outcome: str,\n",
        "                         predictors: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze potential predictors of outcomes\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        outcome : str\n",
        "            Name of the outcome variable\n",
        "        predictors : List[str]\n",
        "            List of predictor variables\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        Dict containing:\n",
        "            - Correlation analysis\n",
        "            - Multiple regression results\n",
        "            - Predictor importance\n",
        "        \"\"\"\n",
        "        from sklearn.linear_model import LinearRegression\n",
        "        from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "        results = {}\n",
        "        outcome_data = self.df[outcome].dropna()\n",
        "\n",
        "        for predictor in predictors:\n",
        "            predictor_data = self.df[predictor].dropna()\n",
        "\n",
        "            # Get common indices\n",
        "            common_idx = outcome_data.index.intersection(predictor_data.index)\n",
        "            if len(common_idx) < 2:\n",
        "                continue\n",
        "\n",
        "            # Correlation analysis\n",
        "            correlation = stats.pearsonr(\n",
        "                outcome_data[common_idx],\n",
        "                predictor_data[common_idx]\n",
        "            )\n",
        "\n",
        "            # Effect size (R²)\n",
        "            r_squared = correlation[0]**2\n",
        "\n",
        "            results[predictor] = {\n",
        "                'correlation': {\n",
        "                    'r': correlation[0],\n",
        "                    'p_value': correlation[1],\n",
        "                    'significant': correlation[1] < self.alpha\n",
        "                },\n",
        "                'effect_size': {\n",
        "                    'r_squared': r_squared,\n",
        "                    'interpretation': self._interpret_r_squared(r_squared)\n",
        "                }\n",
        "            }\n",
        "\n",
        "        return results\n",
        "\n",
        "    @staticmethod\n",
        "    def _interpret_effect_size(eta_squared: float) -> str:\n",
        "        \"\"\"Interpret partial eta-squared effect size\"\"\"\n",
        "        if eta_squared < 0.01:\n",
        "            return 'negligible'\n",
        "        elif eta_squared < 0.06:\n",
        "            return 'small'\n",
        "        elif eta_squared < 0.14:\n",
        "            return 'medium'\n",
        "        else:\n",
        "            return 'large'\n",
        "\n",
        "    @staticmethod\n",
        "    def _interpret_icc(icc: float) -> str:\n",
        "        \"\"\"Interpret ICC values\"\"\"\n",
        "        if icc < 0.50:\n",
        "            return 'poor'\n",
        "        elif icc < 0.75:\n",
        "            return 'moderate'\n",
        "        elif icc < 0.90:\n",
        "            return 'good'\n",
        "        else:\n",
        "            return 'excellent'\n",
        "\n",
        "    @staticmethod\n",
        "    def _interpret_kappa(kappa: float) -> str:\n",
        "        \"\"\"Interpret Kappa values\"\"\"\n",
        "        if kappa < 0.20:\n",
        "            return 'slight'\n",
        "        elif kappa < 0.40:\n",
        "            return 'fair'\n",
        "        elif kappa < 0.60:\n",
        "            return 'moderate'\n",
        "        elif kappa < 0.80:\n",
        "            return 'substantial'\n",
        "        else:\n",
        "            return 'almost perfect'\n",
        "\n",
        "    @staticmethod\n",
        "    def _interpret_r_squared(r_squared: float) -> str:\n",
        "        \"\"\"Interpret R-squared values\"\"\"\n",
        "        if r_squared < 0.02:\n",
        "            return 'negligible'\n",
        "        elif r_squared < 0.13:\n",
        "            return 'small'\n",
        "        elif r_squared < 0.26:\n",
        "            return 'medium'\n",
        "        else:\n",
        "            return 'large'\n"
      ],
      "metadata": {
        "id": "myz_9k3U7xM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import statsmodels.api as sm\n",
        "#Instead of:\n",
        "#from scipy.stats import power_analysis\n",
        "#Import the function using:\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "from typing import Dict, List, Tuple, Optional, Union\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class TransplantAdvancedAnalytics:\n",
        "    \"\"\"\n",
        "    Advanced analytics including machine learning, power analysis,\n",
        "    and predictive modeling for transplant study data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_analyzer, stats_analyzer):\n",
        "        \"\"\"\n",
        "        Initialize with base and statistics analyzers\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        base_analyzer : TransplantStudyAnalyzer\n",
        "            Instance of base analyzer with cleaned data\n",
        "        stats_analyzer : TransplantStudyStatistics\n",
        "            Instance of statistics analyzer\n",
        "        \"\"\"\n",
        "        self.base = base_analyzer\n",
        "        self.stats = stats_analyzer\n",
        "        self.df = base_analyzer.clean_df\n",
        "        self.scaler = StandardScaler()\n",
        "        self.imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "    def predict_outcomes(self,\n",
        "                        target: str,\n",
        "                        features: List[str],\n",
        "                        test_size: float = 0.2) -> Dict:\n",
        "        \"\"\"\n",
        "        Build predictive model for specified outcomes\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        target : str\n",
        "            Target variable to predict\n",
        "        features : List[str]\n",
        "            List of predictor variables\n",
        "        test_size : float\n",
        "            Proportion of data to use for testing\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        Dict containing model performance metrics and feature importance\n",
        "        \"\"\"\n",
        "        from sklearn.model_selection import train_test_split\n",
        "\n",
        "        # Prepare data\n",
        "        X = self.df[features].copy()\n",
        "        y = self.df[target].copy()\n",
        "\n",
        "        # Handle missing values\n",
        "        X = self.imputer.fit_transform(X)\n",
        "        X = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=42\n",
        "        )\n",
        "\n",
        "        # Train models\n",
        "        models = {\n",
        "            'rf': RandomForestRegressor(random_state=42),\n",
        "            'linear': sklearn.linear_model.LinearRegression()\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for name, model in models.items():\n",
        "            # Train and evaluate\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            # Calculate metrics\n",
        "            results[name] = {\n",
        "                'r2': r2_score(y_test, y_pred),\n",
        "                'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "                'cv_scores': cross_val_score(\n",
        "                    model, X, y, cv=5, scoring='r2'\n",
        "                ).mean()\n",
        "            }\n",
        "\n",
        "            # Add feature importance for RF\n",
        "            if name == 'rf':\n",
        "                results[name]['feature_importance'] = dict(\n",
        "                    zip(features, model.feature_importances_)\n",
        "                )\n",
        "\n",
        "        return results\n",
        "\n",
        "    def power_analysis(self,\n",
        "                      effect_size: float,\n",
        "                      alpha: float = 0.05,\n",
        "                      power: float = 0.8) -> Dict:\n",
        "        \"\"\"\n",
        "        Perform power analysis for different statistical tests\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        effect_size : float\n",
        "            Expected effect size\n",
        "        alpha : float\n",
        "            Significance level\n",
        "        power : float\n",
        "            Desired statistical power\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        Dict containing required sample sizes for different tests\n",
        "        \"\"\"\n",
        "        from scipy.stats import norm\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        # T-test\n",
        "        # Initialize the power analysis object\n",
        "        power_analysis_obj = TTestIndPower()\n",
        "\n",
        "        # Calculate the sample size\n",
        "        sample_size = power_analysis_obj.solve_power(\n",
        "            effect_size=effect_size,\n",
        "            alpha=alpha,\n",
        "            power=power\n",
        "        )\n",
        "        results['t_test'] = {\n",
        "            'sample_size': sample_size\n",
        "        }\n",
        "\n",
        "        # ANOVA\n",
        "        results['anova'] = {\n",
        "            'sample_size': self._calculate_anova_sample_size(\n",
        "                effect_size, alpha, power, groups=3\n",
        "            )\n",
        "        }\n",
        "\n",
        "        # Correlation\n",
        "        results['correlation'] = {\n",
        "            'sample_size': self._calculate_correlation_sample_size(\n",
        "                effect_size, alpha, power\n",
        "            )\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def trend_analysis(self,\n",
        "                      measure: str,\n",
        "                      time_col: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze trends over time using time series methods\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        measure : str\n",
        "            Measure to analyze\n",
        "        time_col : str\n",
        "            Column containing time information\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        Dict containing trend analysis results\n",
        "        \"\"\"\n",
        "        # Sort data by time\n",
        "        data = self.df.sort_values(time_col)[[time_col, measure]].dropna()\n",
        "\n",
        "        if len(data) < 3:\n",
        "            return {'error': 'Insufficient data points'}\n",
        "\n",
        "        # Fit trend line\n",
        "        X = sm.add_constant(range(len(data)))\n",
        "        model = sm.OLS(data[measure], X).fit()\n",
        "\n",
        "        # Test for serial correlation\n",
        "        dw_test = sm.stats.diagnostic.acorr_durbin_watson(\n",
        "            model.resid, len(model.params)\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'trend': {\n",
        "                'coefficient': model.params[1],\n",
        "                'p_value': model.pvalues[1],\n",
        "                'significant': model.pvalues[1] < 0.05\n",
        "            },\n",
        "            'model_fit': {\n",
        "                'r_squared': model.rsquared,\n",
        "                'adj_r_squared': model.rsquared_adj\n",
        "            },\n",
        "            'durbin_watson': {\n",
        "                'statistic': dw_test,\n",
        "                'autocorrelation': 'positive' if dw_test < 2 else 'negative'\n",
        "            },\n",
        "            'forecast': self._generate_forecast(model, data, measure)\n",
        "        }\n",
        "\n",
        "    def cluster_analysis(self,\n",
        "                        features: List[str],\n",
        "                        n_clusters: int = 3) -> Dict:\n",
        "        \"\"\"\n",
        "        Perform cluster analysis to identify patient subgroups\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        features : List[str]\n",
        "            Features to use for clustering\n",
        "        n_clusters : int\n",
        "            Number of clusters to create\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        Dict containing clustering results and characteristics\n",
        "        \"\"\"\n",
        "        from sklearn.cluster import KMeans\n",
        "        from sklearn.metrics import silhouette_score\n",
        "\n",
        "        # Prepare data\n",
        "        X = self.df[features].copy()\n",
        "        X = self.imputer.fit_transform(X)\n",
        "        X = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Perform clustering\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "        clusters = kmeans.fit_predict(X)\n",
        "\n",
        "        # Analyze clusters\n",
        "        results = {\n",
        "            'silhouette_score': silhouette_score(X, clusters),\n",
        "            'cluster_sizes': np.bincount(clusters),\n",
        "            'cluster_centers': dict(\n",
        "                zip(features, kmeans.cluster_centers_.T)\n",
        "            ),\n",
        "            'cluster_characteristics': self._analyze_clusters(\n",
        "                features, clusters\n",
        "            )\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def generate_report(self) -> Dict:\n",
        "        \"\"\"Generate comprehensive analysis report\"\"\"\n",
        "        report = {\n",
        "            'predictive_modeling': self.predict_outcomes(\n",
        "                'ast_total_score',\n",
        "                ['ba_age', 'gad7_total', 'phq9_total']\n",
        "            ),\n",
        "            'power_analysis': self.power_analysis(\n",
        "                effect_size=0.5\n",
        "            ),\n",
        "            'trend_analysis': self.trend_analysis(\n",
        "                'ast_total_score',\n",
        "                'patient_profile_timestamp'\n",
        "            ),\n",
        "            'clustering': self.cluster_analysis(\n",
        "                ['ast_total_score', 'ba_age', 'gad7_total']\n",
        "            )\n",
        "        }\n",
        "\n",
        "        return report\n",
        "\n",
        "    def create_advanced_visualizations(self) -> Dict:\n",
        "        \"\"\"Create advanced visualization suite\"\"\"\n",
        "        figs = {}\n",
        "\n",
        "        # 1. Predictive Model Performance\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "        model_results = self.predict_outcomes(\n",
        "            'ast_total_score',\n",
        "            ['ba_age', 'gad7_total', 'phq9_total']\n",
        "        )\n",
        "\n",
        "        # Plot R² scores\n",
        "        r2_scores = [res['r2'] for res in model_results.values()]\n",
        "        axes[0].bar(['Random Forest', 'Linear'], r2_scores)\n",
        "        axes[0].set_title('Model R² Scores')\n",
        "\n",
        "        # Plot feature importance\n",
        "        rf_importance = model_results['rf']['feature_importance']\n",
        "        axes[1].bar(rf_importance.keys(), rf_importance.values())\n",
        "        axes[1].set_title('Feature Importance')\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        figs['model_performance'] = fig\n",
        "\n",
        "        # 2. Cluster Analysis\n",
        "        cluster_results = self.cluster_analysis(\n",
        "            ['ast_total_score', 'ba_age', 'gad7_total']\n",
        "        )\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        ax.bar(range(len(cluster_results['cluster_sizes'])),\n",
        "               cluster_results['cluster_sizes'])\n",
        "        ax.set_title('Cluster Sizes')\n",
        "        ax.set_xlabel('Cluster')\n",
        "        ax.set_ylabel('Number of Patients')\n",
        "\n",
        "        figs['clustering'] = fig\n",
        "\n",
        "        return figs"
      ],
      "metadata": {
        "id": "hx39KcrX9DSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WVzUAMJW9Gj7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}